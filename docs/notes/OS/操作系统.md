# 操作系统

## Overview

> 2023 / 09 / 19

### Definition

计算机用户和计算机硬件之间的中介程序。

A resource allocator, a control program.

### Startup

此时需要 **bootstrap program** 初始化操作系统并加载。通常被存储在 ROM 或 EPROM 中，也叫做 firmware。

### Trap

软中断。由程序错误 (error，例如，除零) 或者用户请求引发 (system call)。

中断分为两种，硬中断 (H/W)，软中断。

为何使用软中断：

+ 封装内存代码，方便调用。
+ 可以对多个 users 的不同操作进行管理与协调。

在 RISC-V 中，所有的中断都称为 traps，分为两类 interrupts (硬中断)，exceptions (异常) & ecalls (环境调用) (即软中断)。

### I / O

同步 (blocked，阻塞)：I / O 设备发起后，用户的进程将不再进行。

异步 (non-block，非阻塞)：尝试读取 I / O 设备状态，但用户程序不会完全中断。

<img src="./操作系统.assets/image-20230921105511504.png" alt="image-20230921105511504" style="zoom:33%;" />

**Device-Status Table**

<img src="./操作系统.assets/image-20230921110624264.png" alt="image-20230921110624264" style="zoom:33%;" />

决定以何种顺序处理多个请求。

### Multiprocessor / Multicore System

多处理器：共享主存。

多核处理器：共享 L2 缓存。

**NUMA**

The CPUs are connected by a shared system interconnect.

<img src="./操作系统.assets/image-20230921112750594.png" alt="image-20230921112750594" style="zoom:33%;" />

### 操作系统结构

**multiprogramming**：可以将多个程序存入主存进行运行，提高 CPU 的利用率。多道程序设计。

**timesharing (multitasking)**：多用户同时分享 CPU 资源，并可以得到相对应的相应。分时系统。

+ 使用 CPU scheduling 规划多程序同时运行。
+ 使用 Swapping 使得大规模的程序 (大于内存空间)，可以运行。
+ 使用 virtual memory 可以程序不完全在内存中运行。

操作系统会有两个 mode。如 User mode 和 kernel mode，用硬件上的一些 bits 进行表征。

+ 一些特权指令只能在 kernel mode 下运行。
+ 两种 mode 进行了隔离，不能同时处在两种状态。

以下为两种模式之间的切换步骤：

<img src="./操作系统.assets/image-20230926164842887.png" alt="image-20230926164842887" style="zoom:33%;" />

call system call 是一种软中断，也称 trap。实际上为程序为用户态提供了一系列的 API。

### 进程管理

进程是指一个程序的执行。程序是一个被动的实体，进程是一个积极的实体。

进程是资源的集合：CPU、内存、I/O、文件、程序的状态数据。

进程又可以分为多个线程，每个线程都会有一个 Program Counter。

CPU 的复用，指的就是多个程序并发地运行。可以分为时分复用和空分复用。

进程种需要解决许多问题，如：进程的同步、交流、创建、删除、防止死锁等。

### 内存管理

**一般情况下**，在运行程序时，数据和指令都需要在内存之中。

进程管理的内容：记录内存的使用状态、内存分配与回收、决定各个进程的内存使用。

### 储存管理

操作系统提供了统一、逻辑的信息存储视图。

储存的单元为文件，每种存储介质均被设备管理。

文件系统中：

+ 可以使用目录结构进行管理。
+ 进行文件访问的管理与控制。

大文件管理中：

+ 通常使用硬盘进行存储。
+ 由操作系统进行管理，进行存储分配和磁盘调度。操作系统的运行速度高度依赖于磁盘调度算法。



==操作系统的目的：抽象 (系统调用)、复用、隔离、共享 (多进程、多用户)、安全、性能、功能==



## OS 结构

> 2023 / 09 / 26

### OS Services

+ **User interface** (UI)：分为 GUI 和 CLI。
+ **Program execution**：包括用户程序和系统程序，能够处理报错。
+ I / O、File system、错误处理、资源分配……

### System Calls

用户模式进入系统模式的唯一方式，trap。

相较 API (Application Program Interface)，system call 更加底层。

POSIX API：Unix、Linux、MacOS 的通用标准，提供系统调用接口。

每种 system call 会被编号。被记录在一张表中，放在 system-call interface。

User 中调用：

<img src="./操作系统.assets/image-20230928102417019.png" alt="image-20230928102417019" style="zoom:33%;" />

高级语言中调用：

<img src="./操作系统.assets/image-20230928102508808.png" alt="image-20230928102508808" style="zoom:33%;" />

都是通过某个 interface 实现状态转换。

内核中 system call 的具体实现向上层封装，可以增加其可移植性。

**参数传递**

+ 寄存器传递，最为简单的方式。

+ 参数较多时，可以存在一个内存中的 Block 或者 table 中，将 Block 或 table 的地址通过寄存器传递。需要注意的是可能传递的地址为虚地址 (两种态之间的传递)，需要经过转换。

  <img src="./操作系统.assets/image-20230928104004988.png" alt="image-20230928104004988" style="zoom:33%;" />

+ 通过栈进行传递。但是栈在两种态下不一定能够共享，该方法不适用于所有的系统。

**分类**：进程管理 (创建 child pid-等待-退出)、文件管理、设备管理、信息维护 (如获取 pid)、交流、权限保护。

### 操作系统的设计和实现

设计的原则：What will be done? 策略 Policy。How to do it? 机制 Mechanism。需要将 Policy 和 Mechanism 分离。

#### 分层结构

<img src="./操作系统.assets/image-20230928112758073.png" alt="image-20230928112758073" style="zoom:33%;" />

但这只是概念模型，实际上不同层级之间仍存在嵌套。

以下为 UNIX 的系统分层概念图。

<img src="./操作系统.assets/image-20230928113038305.png" alt="image-20230928113038305" style="zoom:33%;" />

UNIX 为宏内核结构。对应的微内核 (仅实现基本的功能)，示意如下：

<img src="./操作系统.assets/image-20230928113247686.png" alt="image-20230928113247686" style="zoom:33%;" />

相比宏内核，许多程序需要在 User Mode 中实现。微内核有时需要通过进程通讯实现操作，效率相比宏内核可能降低。但微内核较为稳定、容易移植等。

现代的操作系统也会使用**内核模块 (LKM)** 这种机制 (Linux 为宏内核，但采用了模块化 + 动态加载的机制)。

<img src="./操作系统.assets/image-20231007102521225.png" alt="image-20231007102521225" style="zoom:33%;" />

可以在需要使用时加载对应的模块到 kernel。

**Exokernel**：外核，内核高度简化，只负责资源分配和低级的硬件操作，必须使用定制的库供上层应用使用。

<img src="./操作系统.assets/image-20231007102846989.png" alt="image-20231007102846989" style="zoom:33%;" />

与微内核的区别在于，通过库而不是消息传递进行程序调用。存在兼容性问题，对于定制库文件不统一，维护难度较高。

### 虚拟机

<img src="./操作系统.assets/image-20231007104630519.png" alt="image-20231007104630519" style="zoom:33%;" />

virtual-machine implementation，也称 hypervisor。

两种虚拟机的方案：Type 1 (bare-metal，虚拟机直接和硬件交互)，type 2 (host，虚拟机依赖于宿主系统)



## 进程

> 2023 / 10 / 07

### 概念

进程：一个正在执行的程序，且需要是被顺序执行。

一个进程由以下几个 sections 组成：

+ text section (程序段、代码段)
+ data section (全局变量)
+ program counter
+ 栈 stack (函数参数、局部变量、返回地址) (地址从高到低)
+ 堆 heap (动态分配的内存) (地址从低到高)

<img src="./操作系统.assets/image-20231007112213993.png" alt="image-20231007112213993" style="zoom:25%;" />

此处的地址为虚拟地址而非物理地址。实际上进程所使用的空间，只有 max 端以及 0 段一小部分的空间，中间大部分不用的空间称为 hole。

==user code 和 kernel 不使用同一个 stack，每个进程都有自己对应的 stacks，以获得更好的隔离性==

### 状态

一个进程有以下几种状态：

+ new：正在被创建
+ running：指令正在被执行
+ waiting：进程在等待 (或 blocked) 一些事件 / 响应 (例如等待键盘响应、磁盘操作完成)
+ ready：进程等待**处理器**进行处理 (可能 CPU 处于非空闲状态)
+ terminate：任务完成

<img src="./操作系统.assets/image-20231007113439065.png" alt="image-20231007113439065" style="zoom:33%;" />

### Process control block (PCB)

需要记录进程的状态、调度以及其他重要信息 (现场)。

PCB 需要创建一种数据结构，其中具体需要记录的部分信息有：Process state、Program counter、Contents of CPU registers、CPU scheduling information、Memory-management information、Accounting information、I/O status information

<img src="./操作系统.assets/image-20231010164426557.png" alt="image-20231010164426557" style="zoom:33%;" />

进程调度时需要保存进程的上下文，使等待结束后的进程可以正常运行。

<img src="./操作系统.assets/image-20231010164745479.png" alt="image-20231010164745479" style="zoom:33%;" />

PCB 存储在 kernel stack 中。

#### 调度队列 Process Scheduling Queues

+ 任务队列 **Job queue** – set of all processes in the system

+ 就绪队列 **Ready queue** – set of all processes residing in main memory, ready and waiting to execute

+ 设备队列 **Device queues** – set of processes waiting for an I/O device，可能会有多个，每个设备对应一个队列

<img src="./操作系统.assets/image-20231010170024599.png" alt="image-20231010170024599" style="zoom:33%;" />

ready queue 实际上也是 CPU queue。

一个 PCB 一次只能出现在一个队列上。程序被顺序执行，而程序要使用 device 只能使用 system call。

一个进程被 timer interrupt 打断，会被重新放入 ready queue。

Job queue 会链接所有的进程，上图中未绘出。

进程会在 queue 之间迁移 migrate。

<img src="./操作系统.assets/image-20231010172530563.png" alt="image-20231010172530563" style="zoom:33%;" />

#### Schedulers

+ **Long-term scheduler** (or job scheduler) – selects which processes should be brought into memory (the ready queue)
+ **Short-term scheduler** (or CPU scheduler) – selects which process should be executed next and allocates CPU

当下，用户取代了 long-term scheduler 的角色。

<img src="./操作系统.assets/image-20231010172855018.png" alt="image-20231010172855018" style="zoom:33%;" />

一般考虑 short-term。

进程 schedule 的速度需要尽量快以减少进程调用的 overhead 时间。

此外还有 **medium-term scheduling**，也称 **swap-in, swap-out**。当内存中的进程占用的空间过多时，需要对内存进行管理。

<img src="./操作系统.assets/image-20231010173343011.png" alt="image-20231010173343011" style="zoom:33%;" />

short-term scheduler 调用非常频繁。约 10 ms 就需要 timer interrupt 进行调度，是为了保证良好的交互性。

+ I/O 绑定，**I/O-bound process** – spends more time doing I/O than computations, many short CPU bursts

+ CPU 绑定，**CPU-bound process** – spends more time doing computations; few very long CPU bursts

#### Context Switch

上下文切换，切换不同的进程。

上下文切换时会 overhead，此时系统不可用。

### 进程创建

父进程可以创建子进程，子进程还可以创建自己的子进程，会形成一颗进程树。

+ 父进程和子进程之间可以选择共享资源的范围 (从共享全部资源到不共享)。

+ 父进程和子进程可能并发进行也可能父进程等待子进程完成。
+ 子进程和父进程的地址空间可能是复制关系 (Linux)，也可以由程序加载。

在 UNIX 中：

+ **fork** system call creates new process

+ **exec** system call used after a **fork** to replace the process’ memory space with a new program

<img src="./操作系统.assets/image-20231012104017049.png" alt="image-20231012104017049" style="zoom:33%;" />

父进程的 pid 为 1 的进程称为 orphan 进程。

一个 fork 的例子如下：

~~~c++
int main()
{
	pid_t  pid;
	/* fork another process */
	pid = fork();
	if (pid < 0) { /* error occurred */
		fprintf(stderr, "Fork Failed");
		exit(-1);
	}
	else if (pid == 0) { /* child process */
		execlp("/bin/ls", "ls", NULL);
	}
	else { /* parent process */
		/* parent will wait for the child 	to complete */
		wait (NULL);
		printf ("Child Complete");
		exit(0);
	}
}
~~~

一个进程树的示意如下：

<img src="./操作系统.assets/image-20231012111048874.png" alt="image-20231012111048874" style="zoom:33%;" />

### 进程终止

分为 exit 和 abort，根据不同的操作系统设计，父进程可能会影响子进程的运行。(linux 不影响)

### 进程的合作与通信

进程通信可以实现信息共享、计算加速、模块化设计。

**Producer-Consumer Problem**

producer process 生产信息，由 consumer process 使用，需要通过 buffer 实现信息的传递。

+ unbounded-buffer：传递信息远小于 buffer 空间。
+ bounded-buffer：buffer 的空间可能会被完全使用。

~~~c++
// shared data
#define BUFFER_SIZE 10
typedef struct {
	. . .
} item;

item buffer[BUFFER_SIZE];
int in = 0;
int out = 0;


// producer / insert
while (true) {   
    Produce an item;
    while (((in + 1) % BUFFER_SIZE == out){}
    /* do nothing -- no free buffers */
    buffer[in] = item;
    in = (in + 1) % BUFFER_SIZE;
}

// consumer / remove
while (true) {
    while (in == out){} //do nothing, nothing to consume
    Remove an item from the buffer;
    item = buffer[out];
    out = (out + 1) % BUFFER_SIZE;
    return item;
}
~~~

**Interprocess Communication IPC**

有两种方式：shared memory 和 message passing。

<img src="./操作系统.assets/image-20231017165122104.png" alt="image-20231017165122104" style="zoom:33%;" />

对于 message passing 这一方式，可以分为 Direct Communication，Indirect Communication。

直接通讯会自动建立两个进程之间的通讯。

Indirect Communication 则会从特定的 mailbox (也称为端口) 中传输信息。

信息传递也可以分为同步和异步的。其中同步意味着需要进行 blocking 的操作。

收发消息时需要建立一个消息队列 (buffer)，当 buffer 的容量为 0  时，发送者必须等待接收者。如果容量是 bounded 的，如果 buffer 满了，sender 也需要等待。如果是 unbounded 则无需等待。



## 线程

> 2023 / 10 / 17

<img src="./操作系统.assets/image-20231017173220397.png" alt="image-20231017173220397" style="zoom:33%;" />

每个线程都代表这一个运行中的 context，有独立的寄存器和栈。不同的线程之间共享代码段、数据、文件。

多线程可以提升软件的响应性与交互性，可以节约、共享资源、提升并发性，更好地适配多核的架构。

### User Thread & Kernel Thread

线程的实现可以只在用户态中实现 (所有 progress，kernel 均视为单线程)。或也可以在内核态下实现。

#### multithreading model

如何实现多线程。

+ many-to-one：多个用户层面的线程最终被映射到了单个内核层面的线程。单个线程的 blocking 会造成所有线程的 blocking。

  <img src="./操作系统.assets/image-20231017174427104.png" alt="image-20231017174427104" style="zoom:33%;" />

+ one-to-one：用户态中创建一个线程，对应地，内核态中也创建一个线程。但若一个进程创建了过多的线程，会影响到系统的运行效率。

  <img src="./操作系统.assets/image-20231017174527588.png" alt="image-20231017174527588" style="zoom:33%;" />

+ many-to-many：内核态中有多个线程，但是不会无限多。

  <img src="./操作系统.assets/image-20231017174702130.png" alt="image-20231017174702130" style="zoom:33%;" />

+ Two-level model：不同的线程重要度不同，对重要的线程使用 one-to-one，非重要线程使用 many-to-many。

  <img src="./操作系统.assets/image-20231019101651707.png" alt="image-20231019101651707" style="zoom:33%;" />

#### signal handling

signal 与 interrupt 的不同在于：interrupt 由 CPU 处理，signal 是一种 IPC 的方式，用于协调 signal 的是 kernel，处理 signal 的每个进程的 signal handler。

#### Thread Pools

线程池。希望对于 process request 的响应能够尽量快。非线程池情况下，响应 request 的流程为收到 request - create thread - 处理 - cancel thread。线程池会直接创建多个线程，收到 request 直接查找空闲线程进行调用。

线程池的大小取决于程序提供的 service 的容量。

#### Scheduler Activations

调度激活。保证 APP 始终可以运行指定数目的 thread。



## CPU Scheduling

> 2023 / 10 / 19

<img src="./操作系统.assets/image-20231019105127746.png" alt="image-20231019105127746" style="zoom:33%;" />

实际上 CPU burst 的时间很短，而 I/O 的时间很长。为提高 CPU 的利用率，需要进行 multi-programming。

CPU Scheduler 在以下的场景中会起作用：

+ 一个进程从 running 进入到 waiting 状态 (I/O 请求或 wait())。
+ 一个进程从 running 进入到 ready 状态 (中断)。
+ 一个进程从 waiting 进入到 ready 状态 (I/O 完成)。
+ 一个进程运行结束。

!!! note
	以上的情况中，1、4 两种情况是 preemptive，2、3 为 nonpreemptive。

### Dispather

将 CPU 的运行时间分派给各个进程。

<img src="./操作系统.assets/image-20231019111104932.png" alt="image-20231019111104932" style="zoom:33%;" />

+ Dispatcher module gives control of the CPU to the process selected by the short-term scheduler; this involves:

  + switching context

  + switching to user mode

  + jumping to the proper location in the user program to restart that program

+ *Dispatch latency* – time it takes for the dispatcher to stop one process and start another running。

!!! note
	Dispatch latency 对于 program 来说是 overhead。

### 调度 / 优化 Criteria

调度效率相关的指标有：

+ CPU utilization (CPU利用率) – keep the CPU as busy as possible

+ Throughput (吞吐率) – # of processes that complete their execution per time unit

+ Turnaround time (周转时间) – amount of time to execute a particular process (从提交到结束运行的全部时间)

+ Waiting time (等待时间) – amount of time a process has been waiting **in the ready queue**

+ Response time (响应时间) – amount of time it takes from when a request was submitted until the ***first* response** is produced, **not** output (for time-sharing environment)

优化时需要达到：

+ Max CPU utilization

+ Max throughput

+ Min turnaround time 

+ Min waiting time 

+ Min response time

### 调度算法

#### Gantt Chart

<img src="./操作系统.assets/image-20231019112845284.png" alt="image-20231019112845284" style="zoom:33%;" />

如上图所示，为 Gantt Chart 的一种。横坐标为时间轴。

#### First-come, First-served FCFS

最为基础的算法，先来的进程先处理。

|                                                              |                                                              |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="./操作系统.assets/image-20231019113357966.png" alt="image-20231019113357966" style="zoom:33%;" /> | 平均等待时间：<br />P1 = 0  P2 = 24  P3 = 27<br />P~avg~ = 17<br />P3 的周转时间是 30 |
| <img src="./操作系统.assets/image-20231019113340227.png" alt="image-20231019113340227" style="zoom:33%;" /> |  平均等待时间：<br />P1 = 6  P2 = 0  P3 = 3<br />P~avg~ = 3  |

#### Shortest-Job-First SJF

对于每个进程，记录下一次 CPU burst time，优先运行时间最短的程序。

分为两种情况：抢占式与非抢占式。

对于非抢占式的调度，调度的时机是在某一进程结束运行时，从当前的 ready queue 中找出时间最短的进程。

<img src="./操作系统.assets/image-20231024163916178.png" alt="image-20231024163916178" style="zoom:33%;" />

!!! warning
	以上的等待时间计算时，需要减去 arrival time。

对于抢占式的调度，调度的时机是新进程到达的时间 / 进程运行结束的时刻，选择剩余 burst time 最短的进程进行调度。

<img src="./操作系统.assets/image-20231024164451811.png" alt="image-20231024164451811" style="zoom:33%;" />

!!! warning
	以上的等待时间计算时，需要考虑被打断后的等待时间，例如 P~1~ 在调度的中间存在 9 的等待时间。

!!! note
	SJF 调度是理论上最优的调度方案。
	但是不可测量 next CPU burst time，需要使用一定的估计方法。例如下图中的方法使用过去的调度时间来估计未来的调度时间。
	<img src="./操作系统.assets/image-20231024165323351.png" alt="image-20231024165323351" style="zoom:45%;" />

#### Priority Scheduling

此处定义编号 (priority number) 越小，优先级越高。

从本质上看，SJF 也是一种 priority scheduling。

+ Problem $\equiv$ Starvation – low priority processes may never execute. 低优先级的进程永远得不到运行。

+ Solution $\equiv$ Aging – as time progresses increase the priority of the process. 随着时间的推移增加等待的进程的 priority。

#### Round Robin RR

面向交互式系统 / 分时系统 (多任务系统) 。

每个进程都分配一个时间单元 (time quantum, q)。若 ready queue 中有 n 个进程，某进程最多等待 (n-1) * q 的时间就会得到调度。

!!! note
	q large -> FIFO
	q small -> q must be large with respect to context switch, otherwise overhead is too high

<img src="./操作系统.assets/image-20231024171644669.png" alt="image-20231024171644669" style="zoom:33%;" />

相比 SJF，可以发现虽然 SJF 的总运行时间短，CPU 效率高，但是相应时间可能不一定优于 RR。

#### Multilevel Queue

Ready Queue 被分为两个队列，前台 (foreground) 以及后台 (background) 两个队列。每个队列有自己的调度算法。

要较好实现需要解决两个问题：

+ 两个队列之间的优先级问题 (例如，是否均为前台应用的优先级高于后台应用)。
+ 两个队列的 CPU 时间的分配 (time slice)。

#### Multilevel Feedback Queue

带反馈的多层队列。例如某一进程在 RR 调度下尚未完成运行，则调度程序会将其切换到另一个队列中继续运行。

原先静态的多级队列可能会导致一些 starving 问题，而“游走”可能可以解决这个问题。

<img src="./操作系统.assets/image-20231024173352255.png" alt="image-20231024173352255" style="zoom:33%;" />

### 线程调度

也称为 contention scope。

+ **Local Scheduling** (**Process**-Contention Scope) – How the threads library decides which thread to put onto an available LWP.

+ **Global Scheduling** (**System**-Contention Scope) – How the kernel decides which kernel thread to run next.



## 进程同步

> 2023 / 10 / 26

### Race Conditon

在之前的 producer-consumer 模型中加入共享变量 count 记录队列中元素的个数。producer 中 ++，consumer 中 --。

具体实现为：

`register1 = count  register1 = register1 + 1  count = register1`

`register2 = count  register2 = register2 - 1  count = register2`

若经过调度后顺序如下：

1. S0: producer execute register1 = count   {register1 = 5}
2. S1: producer execute register1 = register1 + 1   {register1 = 6} 
3. S2: consumer execute register2 = count   {register2 = 5} 
4. S3: consumer execute register2 = register2 - 1   {register2 = 4} 
5. S4: producer execute count = register1   {count = 6 } 
6. S5: consumer execute count = register2   {count = 4}

count 的值不符合期望。

**Critical Section**：可能由于共享内存产生冲突的部分 (但也存在不访问共享内存的部分)。大致的模型如下：

~~~c
do {
    /* Entry section here */
    // Critical section
    /* Exit section here */
    // Remainder section
} while(TRUE);
~~~

若 Critical section 中的 statements 若在操作不同的 data item，可以将其分解为更细粒度的 critical section。细粒度的 critical section 可以有更好的并发性。

Critical section 需要满足三个条件：

**互斥性** (mutual exclusion)，若一个进程在运行 critical section，与该进程存在合作关系的进程不可运行。

**Progress**，如果当前合作的进程中，没有进程处于 critical section 中，存在接下来希望进入 critical section 的几个进程，需要保证进程进入 critical section 不会被永久延迟 (有限时间内选择出执行 critical section 的进程)。

**有限等待** (Bounded Waiting)，一个进程发出请求执行 critical section (已经进入 entry section)，需要等待的时间一定是有限的。

+ 假设每个进程运行速度一定非 0。但无进程间相对运行速度的假设。

软件方法 -- **Peterson's Solution**

~~~c++
int turn; 
Boolean flag[2];
// for P_i (另一个进程为 P_j, 类似)
while (true) {
    flag[i] = TRUE;
    turn = j;
    while ( flag[j] && turn == j);
    	// CRITICAL SECTION
    flag[i] = FALSE;
    	// REMAINDER SECTION
}
~~~

硬件方法：**关闭中断** (若 critical section不能正常执行，中断无法开启；多核或多处理器的情况下，关闭中断代价较高)，**Atomic 指令** (执行时不允许中断)。

**TestAndSet solution**

~~~c
boolean TestAndSet (boolean *target) {
    boolean rv = *target;
    *target = TRUE;
    return rv:
}
while (true) {
    while (TestAndSet(&lock))
        ;   /* do nothing */
    // critical section
    lock = FALSE;
    // remainder section 
}
~~~

但是以上的方法不满足有限等待，可能会产生 starving 的问题。例如进程 1 3 互相抢占，进程 2 starving。

**Swap Instruction**

~~~c
void Swap (boolean *a, boolean *b) {
    boolean temp = *a;
    *a = *b;
    *b = temp:
}
while (true)  {
    key = TRUE;
    while ( key == TRUE)
        Swap (&lock, &key );
    // critical section
    lock = FALSE;
    // remainder section 
}

~~~

与 TestAndSet 类似，依然不满足有限等待。

### Semaphore

semaphore S 为一个整型变量。

有两个基础的 atomic 操作：wait() 和 signal()。

~~~c
S.wait() { 
while S <= 0
	; // no-op
S--;
}
~~~

~~~c
S.signal() { 
	S++;
}
~~~

若有多个进程同时处于 wait 的循环之中，S 被置为 1，由于 wait() 是原子操作，则某一进程退出循环后将会将 S 重新置为 0，其余进程将继续等待。

+ counting semaphore：S 为整形变量。
+ binary semaphore (mutex locks) ：S 只能为 0 或者 1。

~~~c
Semaphore S;    //  initialized to 1
wait (S);
// Critical Section
signal (S);
~~~

Semaphore 可用于指定进程之间的调用顺序。

~~~c
Semaphore S;    //  initialized to 0
P1:	S1
    S.Signal()
P2: S.Wait()
    S2
~~~

以上场景中，希望 S1 在 S2 之前运行，将 S 初始化为 0，可以实现目的。

由于需要保证 Wait() 和 Signal() 不能同时执行，wait 和 signal 操作也需要作为临界区代码执行。一种执行方式是加锁，进行忙等待。

另一种方式是可以不使用忙等待，利用 OS 本身的上下文切换机制。

~~~c
wait (S){ 
    value--;
    if (value < 0)
        // add this process to waiting queue
        block();  
}
Signal (S){ 
    value++;
    if (value <= 0)
        // remove a process P from the waiting queue
        wakeup(P);  
}
~~~

使用信号量依然可能出现 deadlock 和 starving 问题。

### Some Problems

#### Bounded-Buffer Problem

+ Semaphore mutex initialized to the value 1

+ Semaphore full initialized to the value 0, counting full items

+ Semaphore empty initialized to the value N, counting empty items.

~~~c
// producer
while (true)  {
    // produce an item
    wait (empty);
    wait (mutex);
    // add the item to the  buffer
    signal (mutex);
    signal (full);
}
// consumer
while (true) {
    wait (full);
    wait (mutex);
    // remove an item from buffer
    signal (mutex);
    signal (empty);
    // consume the removed item
}
~~~

#### Readers-Writers Problem

有多个 Reader 和多个 Writer。读操作可以并发，但一旦有写操作，只能由当前需要写的进程进行访问。

+ Semaphore mutex initialized to 1, to ensure mutual exclusion when readcount is updated.

+ Semaphore wrt initialized to 1.

+ Integer readcount initialized to 0.

~~~c
// writers
while (true) {
    wait (wrt) ;
    // writing is performed
    signal (wrt) ;
}
// readers
while (true) {
    wait (mutex) ;
    readcount++ ;
    if (readcount == 1)  wait (wrt) ;
    signal (mutex);
    // reading is performed
    wait (mutex) ;
    readcount-- ;
    if (readcount  == 0)  signal (wrt) ;
    signal (mutex) ;
}
~~~

只有第一个 reader 需要进行 wrt 的 wait 和 释放。

#### Dining-Philosophers Problem

<img src="./操作系统.assets/image-20231109100942121.png" alt="image-20231109100942121" style="zoom:33%;" />

五个哲学家，5 **支**不同的筷子。只有当哲学家饥饿时，才会试图拿起自己左右两根筷子。

~~~c
// Philosopher i
While (true) { 
    wait (chopstick[i]);
    wait (chopStick[(i + 1) % 5]);
    //  eat
    signal (chopstick[i]);
    signal (chopstick[(i + 1) % 5]);
    //  think
}
// 上述代码可能发生死锁，当所有哲学家同时取同一侧的筷子时
~~~

只需要更改取筷子的顺序即可。一部分哲学家先取左侧的筷子，一部分先取右侧的筷子即可。

### Monitor 管程

一种高层抽象的机制，实现线程之间的同步。

~~~c
monitor monitor-name
{
	// shared variable declarations
    // Only one process may be active within the monitor at a time
	procedure P1 (…) { …. }
	…
	procedure Pn (…) {……}
    Initialization code ( ….) { … }
	…
}
~~~

<img src="./操作系统.assets/image-20231109102253791.png" alt="image-20231109102253791" style="zoom:33%;" />

除了正在运行的程序，其他程序处于 Queue 中等待进入。

#### Condition Variable

一个进程进入管程后被阻塞，阻塞的原因定义为条件变量。原因可能有多个，故可能有多个条件变量队列。

+ Two operations on a condition variable:

  + **x.wait ()**  – x 条件不满足，正在调用 monitor 的进程使用该操作将自己插入 x 的等待队列，释放管程，其余进程也可进入。

  + **x.signal ()** – x 条件变化。调用该操作。唤醒一个被 x.wait() 阻塞的进程。

<img src="./操作系统.assets/image-20231109102604555.png" alt="image-20231109102604555" style="zoom:33%;" />

~~~c++
monitor Demo {
    共享数据结构 S;
    init() {...}
    take_away() {
        // 资源不够，在 x 上阻塞等待
        if(S <= 0) x.wait();
        // 资源足够，则进行处理
        ...
    }
    give_back() {
        //规划资源
        ...
        if(有等待进程) 
            // 唤醒进程
            x.signal()
    }
}
~~~



## Deadlock

> 2023 / 11 / 09

由于多个进程的并发执行，多个进程因竞争造成一种互相等待的情况，若无外力干涉无法推进。

| <img src="./操作系统.assets/image-20231109105730801.png" alt="image-20231109105730801" style="zoom:27%;" /> | <img src="./操作系统.assets/image-20231109105744106.png" alt="image-20231109105744106" style="zoom:27%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: |

死锁的原因：存在资源的共享。

**系统模型**：

+ 有资源 R~1~ ~ R~m~，CPU cycles, memory space, I/O devices 等，每种资源有多个实例 W~i~
+ 遵循 request - use - release 协议

在上述的系统模型之下，死锁的条件为 (均需满足)：

+ **Mutual exclusion:** only one process at a time can use a resource.

+ **Hold and wait:** a process holding at least one resource is waiting to acquire additional resources held by other processes.

+ **No preemption:** a resource can be released only voluntarily by the process holding it, after that process has completed its task.

+ **Circular wait:** there exists a set {*P*0, *P*1, …, *P*n} of waiting processes such that *P*0 is waiting for a resource that is held by *P*1, *P*1 is waiting for a resource that is held by *P*2, …, *P**n*–1 is waiting for a resource that is held by *P*n, and *P*n is waiting for a resource that is held by *P*0.

### Resource-Allocation Graph

A set of vertices *V* and a set of edges *E*.

V is partitioned into two types:

+ *P* = {*P*1, *P*2, …, *Pn*}, the set consisting of all the processes in the system.

+ *R* = {*R*1, *R*2, …, *Rm*}, the set consisting of all resource types in the system.

request edge – directed edge *P*1 $\to$ *Rj*

assignment edge – directed edge *Rj* $\to$ *Pi*

|                           Process                            |                Resource Type with 4 instances                |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="./操作系统.assets/image-20231109110944194.png" alt="image-20231109110944194" style="zoom:33%;" /> | <img src="./操作系统.assets/image-20231109110954120.png" alt="image-20231109110954120" style="zoom:33%;" /> |
|              ***Pi* requests instance of *Rj***              |           ***Pi* is holding an instance of *Rj***            |
| <img src="./操作系统.assets/image-20231109111034981.png" alt="image-20231109111034981" style="zoom:33%;" /> | <img src="./操作系统.assets/image-20231109111015938.png" alt="image-20231109111015938" style="zoom:33%;" /> |

!!!warning
	+ 没有环路一定无死锁，有环路不一定有死锁
	+ 有环路：
	+ 	if only one instance per resource type, then deadlock.
	+	 if several instances per resource type, possibility of deadlock.

### 死锁处理

#### 死锁预防

使系统不会产生死锁的情况。使死锁的 4 个条件中有条件无法完成。

具体来说需要避免 circute wait 的产生：将所有的 resource type 都进行编号，使所有的资源只能序号从低到高地申请。但通常在现实地 OS 中不可能这样操作。

#### 死锁避免

仍属于预防范畴，但不是去避开死锁条件，而是防止进入系统“不安全状态”。

**系统安全状态**：在资源分配时检查是否安全。

+ 系统能按照某种顺序推进程序，并提供相应的资源，直至每个进程对资源的最大需求被满足。
+ 若找不到这样的序列，则说明系统不安全。
+ 不安全不一定死锁。

<img src="./操作系统.assets/image-20231109112832889.png" alt="image-20231109112832889" style="zoom:33%;" />

若每种资源只有一个实例，使用 RAG。

<img src="./操作系统.assets/image-20231109113226864.png" alt="image-20231109113226864" style="zoom:33%;" />

虚线为 claim edge 未来可能会 request。实线表示 request 和 assign。

每次分配时需要检查系统是否存在环路 (包括 claim)，若存在，需要拒绝最近的 request。

若每种资源有多个实例，使用 **banker's algorithm**。

将操作系统视为银行家，操作系统管理的资源相当于银行的资金。进程请求资源视为贷款。需要保证不出现资金短缺的情况。

有几点前提：

+ 每种资源有多个实例。
+ 每个进程事先声明了自己的最大资源使用量。
+ 申请资源时，进程有可能会等待。
+ 进程得到了需要的资源时，会在有限的时间内会归还资源。

***n*** = number of processes, and ***m*** = number of resources types

1. Avaliable 数组，表示各类资源的可用实例，若 Avaliable[j] = k，R~j~ 类型的资源有 k 个实例可供调用。
2. Max\[n]\[m] 矩阵，一行一个进程，一列一种资源，表示最大的需求量。
3. Allocation\[n]\[m] 矩阵，进程已经分配到的资源。
4. Need\[n]\[m] 矩阵，进程接下来最多还需要多少资源。

$Need[i,j]=Max[i,j]-Allocation[i,j]$

`Safety algorithm`

Work\[m] 表示剩余可用的资源，初始化为 Avaliable。

Finish\[n] 表示每个进程是否结束，一开始均设为 false。

1. 若存在 i 使得，Finish\[i] = false，Need[i] <= work，正常运行。若不存在，则转到第三步。
2. Work += Allocation，Finish[i] = true，回到第一步。
3. 若 Finish[n] 全是 true，系统处于安全状态。

`Resource-Request Algorithm`

Request~i~[m] 为进程 P~i~  的请求向量。

1. 若 Request~i~[j] <= Need[i, j]，跳转 2。若不是，视为出错。

2. 若 Request~i~[j] <= Avaliable[i, j]，跳转 3。否则进程需要等待资源。

3. 系统试探性地分配资源。

   $$ Avaliable = Avaliable - Request; \\ Allocation[i,j] = Allocation[i,j]+Request_i[j] \\ Need[i,j] = Need[i,j]-Request_i[j] $$

4. 使用 Safety Algorithm 检查是否安全，若安全，则分配；不安全，则回退。

#### 死锁检测

**Wait-for Graph**

<img src="./操作系统.assets/image-20231114171503241.png" alt="image-20231114171503241" style="zoom:33%;" />

单实例地情况下若 Wait-for graph 中存在有向环路，则有死锁。

**多实例检测**

1. Avaliable[m]
2. Allocation\[n][m] 当前的分配情况。
3. Request\[n][m] 当前的请求情况。

Work\[m] 表示剩余可用的资源，初始化为 Avaliable。

Finish\[n] 表示每个进程是否结束，一开始，若 Allocation[i] == 0，则设为 true，不然为 false。

Detection Algorithm 如下：

1. 若存在 i 使得，Finish\[i] = false，Need[i] <= work，正常运行。若不存在，则转到第三步。
2. Work += Allocation，Finish[i] = true，回到第一步。
3. 若 Finish[i] == false，则进程 P~i~ 死锁。

#### 死锁恢复

+ Abort all deadlocked processes.
+ Abort one process at a time until the deadlock cycle is eliminated.
